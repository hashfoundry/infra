# 180. Service mesh Ğ² production

## ğŸ¯ Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ
ĞšĞ°ĞºĞ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ service mesh Ğ² production?

## ğŸ’¡ ĞÑ‚Ğ²ĞµÑ‚

Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ service mesh Ğ² production Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹, Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ canary deployments, resource planning, security hardening, disaster recovery Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ mesh Ğ² ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸ÑÑ….

### ğŸ—ï¸ Production-ready Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

#### 1. **Ğ¡Ñ…ĞµĞ¼Ğ° production deployment**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Production Service Mesh Architecture          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                Control Plane (HA)                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚   Istiod    â”‚  â”‚   Istiod    â”‚  â”‚   Istiod    â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ (Primary)   â”‚  â”‚ (Replica)   â”‚  â”‚ (Replica)   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚   Zone-A    â”‚  â”‚   Zone-B    â”‚  â”‚   Zone-C    â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚           â”‚               â”‚               â”‚            â”‚ â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â”‚                           â”‚                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚              Load Balancer                         â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                              â”‚
â”‚                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                  Data Plane                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚                Production Zone A                   â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Service A   â”‚  â”‚ Service B   â”‚  â”‚ Service C   â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚                Production Zone B                   â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Service D   â”‚  â”‚ Service E   â”‚  â”‚ Service F   â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚                Production Zone C                   â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Service G   â”‚  â”‚ Service H   â”‚  â”‚ Service I   â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚  â”‚ + Envoy     â”‚ â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                              â”‚
â”‚                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Observability Stack                       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚ Prometheus  â”‚  â”‚   Jaeger    â”‚  â”‚   Grafana   â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ (Metrics)   â”‚  â”‚ (Tracing)   â”‚  â”‚(Dashboards) â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚    Kiali    â”‚  â”‚ AlertManagerâ”‚  â”‚    Loki     â”‚     â”‚ â”‚
â”‚  â”‚  â”‚ (Topology)  â”‚  â”‚  (Alerts)   â”‚  â”‚   (Logs)    â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. **Production requirements**
```yaml
# Production requirements Ğ´Ğ»Ñ service mesh
production_requirements:
  high_availability:
    control_plane:
      - "Multi-zone deployment"
      - "Leader election"
      - "Automatic failover"
      - "Health checks"
    
    data_plane:
      - "Circuit breakers"
      - "Retry policies"
      - "Timeout configuration"
      - "Load balancing"
  
  performance:
    latency:
      - "P99 < 100ms overhead"
      - "Service discovery < 50ms"
      - "Configuration propagation < 5s"
    
    throughput:
      - "Support 10k+ RPS per service"
      - "Efficient resource utilization"
      - "Horizontal scaling"
    
    resource_usage:
      - "Sidecar memory < 100MB"
      - "Control plane CPU < 2 cores"
      - "Network overhead < 5%"
  
  security:
    encryption:
      - "mTLS everywhere"
      - "Certificate rotation"
      - "Strong cipher suites"
    
    authorization:
      - "Zero-trust policies"
      - "RBAC integration"
      - "Audit logging"
    
    compliance:
      - "SOC 2 compliance"
      - "GDPR compliance"
      - "Industry standards"
  
  observability:
    metrics:
      - "Golden signals monitoring"
      - "SLI/SLO tracking"
      - "Custom business metrics"
    
    tracing:
      - "End-to-end tracing"
      - "Performance analysis"
      - "Error tracking"
    
    logging:
      - "Structured logging"
      - "Log aggregation"
      - "Security events"
  
  operational:
    deployment:
      - "Blue-green deployments"
      - "Canary releases"
      - "Rollback procedures"
    
    maintenance:
      - "Zero-downtime upgrades"
      - "Configuration management"
      - "Disaster recovery"
```

### ğŸ“Š ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· Ğ½Ğ°ÑˆĞµĞ³Ğ¾ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°

#### Production deployment ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° production readiness
kubectl get pods -n istio-system -o wide
kubectl get nodes --show-labels

# ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ production Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
kubectl port-forward -n monitoring svc/prometheus 9090:9090
kubectl port-forward -n monitoring svc/grafana 3000:3000

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° HA ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
kubectl get pods -n istio-system -l app=istiod --show-labels
kubectl describe service istiod -n istio-system
```

### ğŸš€ Production deployment ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ

#### 1. **ĞŸĞ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ°Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ**
```bash
#!/bin/bash
# production-migration.sh

echo "ğŸš€ Production Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Service Mesh"

# ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ
MIGRATION_PHASE=${1:-"phase1"}
NAMESPACE=${2:-"production"}

# Phase 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹
phase1_infrastructure() {
    echo "ğŸ“‹ Phase 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹"
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Istio Ğ² production Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ
    cat <<EOF | kubectl apply -f -
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: production
  namespace: istio-system
spec:
  values:
    global:
      meshID: production-mesh
      cluster: hashfoundry-production
      network: production-network
    pilot:
      env:
        PILOT_ENABLE_WORKLOAD_ENTRY_AUTOREGISTRATION: true
        PILOT_ENABLE_CROSS_CLUSTER_WORKLOAD_ENTRY: true
        PILOT_TRACE_SAMPLING: 1.0
    telemetryV2:
      enabled: true
      prometheus:
        configOverride:
          metric_relabeling_configs:
          - source_labels: [__name__]
            regex: 'istio_.*'
            target_label: __tmp_istio_metric
          - source_labels: [__tmp_istio_metric]
            regex: '.*'
            target_label: __name__
            replacement: '${1}'
  components:
    pilot:
      k8s:
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        hpaSpec:
          minReplicas: 3
          maxReplicas: 10
          metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 70
        podDisruptionBudget:
          minAvailable: 2
    ingressGateways:
    - name: istio-ingressgateway
      enabled: true
      k8s:
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 2000m
            memory: 1Gi
        hpaSpec:
          minReplicas: 3
          maxReplicas: 10
        service:
          type: LoadBalancer
          loadBalancerSourceRanges:
          - "10.0.0.0/8"
          - "172.16.0.0/12"
          - "192.168.0.0/16"
    egressGateways:
    - name: istio-egressgateway
      enabled: true
      k8s:
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        hpaSpec:
          minReplicas: 2
          maxReplicas: 5
EOF
    
    # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
    kubectl wait --for=condition=available deployment/istiod -n istio-system --timeout=600s
    
    echo "âœ… Phase 1 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
}

# Phase 2: Pilot services
phase2_pilot_services() {
    echo "ğŸ§ª Phase 2: Pilot services"
    
    # Ğ’Ñ‹Ğ±Ğ¾Ñ€ pilot ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² (Ğ½ĞµĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ)
    local pilot_services=("logging-service" "metrics-collector" "health-checker")
    
    for service in "${pilot_services[@]}"; do
        echo "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ pilot ÑĞµÑ€Ğ²Ğ¸ÑĞ°: $service"
        
        # Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ sidecar injection
        kubectl patch deployment $service -n $NAMESPACE -p '{"spec":{"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"true"}}}}}'
        
        # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ rollout
        kubectl rollout status deployment/$service -n $NAMESPACE --timeout=300s
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ
        kubectl get pods -n $NAMESPACE -l app=$service
        
        # Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ connectivity
        local pod=$(kubectl get pods -n $NAMESPACE -l app=$service -o jsonpath='{.items[0].metadata.name}')
        kubectl exec $pod -n $NAMESPACE -c istio-proxy -- curl -s http://health-check:8080/health
        
        echo "âœ… $service Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"
    done
    
    echo "âœ… Phase 2 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
}

# Phase 3: Core services
phase3_core_services() {
    echo "ğŸ—ï¸ Phase 3: Core services"
    
    # Core services (Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ, Ğ½Ğ¾ Ğ½Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ)
    local core_services=("user-service" "notification-service" "analytics-service")
    
    for service in "${core_services[@]}"; do
        echo "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ core ÑĞµÑ€Ğ²Ğ¸ÑĞ°: $service"
        
        # Canary deployment
        kubectl patch deployment $service -n $NAMESPACE -p '{"spec":{"replicas":6}}'
        kubectl rollout status deployment/$service -n $NAMESPACE
        
        # Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ sidecar Ğ´Ğ»Ñ 50% pods
        kubectl patch deployment $service -n $NAMESPACE -p '{"spec":{"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"true"}}}}}'
        
        # ĞŸĞ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
        kubectl patch deployment $service -n $NAMESPACE -p '{"spec":{"strategy":{"rollingUpdate":{"maxSurge":"25%","maxUnavailable":"25%"}}}}'
        kubectl rollout status deployment/$service -n $NAMESPACE --timeout=600s
        
        # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        echo "ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ´Ğ»Ñ $service..."
        sleep 60
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° error rate
        local error_rate=$(kubectl exec -n istio-system deployment/prometheus -- \
            promtool query instant "rate(istio_requests_total{destination_service_name=\"$service\",response_code!~\"2.*\"}[5m])" | \
            grep -o '[0-9.]*' | head -1)
        
        if (( $(echo "$error_rate > 0.01" | bc -l) )); then
            echo "âŒ Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ error rate Ğ´Ğ»Ñ $service: $error_rate"
            # Rollback
            kubectl rollout undo deployment/$service -n $NAMESPACE
            exit 1
        fi
        
        echo "âœ… $service Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾"
    done
    
    echo "âœ… Phase 3 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
}

# Phase 4: Critical services
phase4_critical_services() {
    echo "ğŸ”¥ Phase 4: Critical services"
    
    # Critical services (Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¾ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸)
    local critical_services=("payment-service" "auth-service" "order-service")
    
    for service in "${critical_services[@]}"; do
        echo "ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ÑĞµÑ€Ğ²Ğ¸ÑĞ°: $service"
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ backup
        kubectl get deployment $service -n $NAMESPACE -o yaml > /tmp/${service}-backup.yaml
        
        # Blue-green deployment
        kubectl patch deployment $service -n $NAMESPACE -p '{"metadata":{"labels":{"version":"blue"}}}'
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ green version Ñ sidecar
        kubectl get deployment $service -n $NAMESPACE -o yaml | \
            sed 's/version: blue/version: green/g' | \
            sed 's/name: '$service'/name: '$service'-green/g' | \
            kubectl apply -f -
        
        kubectl patch deployment ${service}-green -n $NAMESPACE -p '{"spec":{"template":{"metadata":{"annotations":{"sidecar.istio.io/inject":"true"}}}}}'
        
        # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ green
        kubectl rollout status deployment/${service}-green -n $NAMESPACE --timeout=600s
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° traffic splitting
        cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: ${service}-traffic-split
  namespace: $NAMESPACE
spec:
  hosts:
  - $service
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: $service
        subset: green
  - route:
    - destination:
        host: $service
        subset: blue
      weight: 90
    - destination:
        host: $service
        subset: green
      weight: 10
---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: ${service}-destination
  namespace: $NAMESPACE
spec:
  host: $service
  subsets:
  - name: blue
    labels:
      version: blue
  - name: green
    labels:
      version: green
EOF
        
        # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ 30 Ğ¼Ğ¸Ğ½ÑƒÑ‚
        echo "ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ $service Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ 30 Ğ¼Ğ¸Ğ½ÑƒÑ‚..."
        for i in {1..30}; do
            sleep 60
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
            local green_error_rate=$(kubectl exec -n istio-system deployment/prometheus -- \
                promtool query instant "rate(istio_requests_total{destination_service_name=\"$service\",destination_version=\"green\",response_code!~\"2.*\"}[5m])")
            
            local green_latency=$(kubectl exec -n istio-system deployment/prometheus -- \
                promtool query instant "histogram_quantile(0.95, rate(istio_request_duration_milliseconds_bucket{destination_service_name=\"$service\",destination_version=\"green\"}[5m]))")
            
            echo "ĞœĞ¸Ğ½ÑƒÑ‚Ğ° $i: Error rate: $green_error_rate, P95 latency: $green_latency"
        done
        
        # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 100% green
        kubectl patch virtualservice ${service}-traffic-split -n $NAMESPACE --type='merge' -p='{"spec":{"http":[{"route":[{"destination":{"host":"'$service'","subset":"green"},"weight":100}]}]}}'
        
        # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ blue version
        kubectl delete deployment $service -n $NAMESPACE
        kubectl patch deployment ${service}-green -n $NAMESPACE -p '{"metadata":{"name":"'$service'"}}'
        
        echo "âœ… $service Ğ¼Ğ¸Ğ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° service mesh"
    done
    
    echo "âœ… Phase 4 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
}

# Phase 5: Ğ¤Ğ¸Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
phase5_finalization() {
    echo "ğŸ¯ Phase 5: Ğ¤Ğ¸Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"
    
    # Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ namespace-wide injection
    kubectl label namespace $NAMESPACE istio-injection=enabled --overwrite
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° production policies
    cat <<EOF | kubectl apply -f -
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: $NAMESPACE
spec:
  mtls:
    mode: STRICT
---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: default
  namespace: $NAMESPACE
spec:
  host: "*.local"
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
EOF
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° observability
    cat <<EOF | kubectl apply -f -
apiVersion: telemetry.istio.io/v1alpha1
kind: Telemetry
metadata:
  name: production-telemetry
  namespace: $NAMESPACE
spec:
  metrics:
  - providers:
    - name: prometheus
  tracing:
  - providers:
    - name: jaeger
  accessLogging:
  - providers:
    - name: otel
EOF
    
    echo "âœ… Phase 5 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"
    echo "ğŸ‰ Production Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!"
}

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°
case "$MIGRATION_PHASE" in
    phase1)
        phase1_infrastructure
        ;;
    phase2)
        phase2_pilot_services
        ;;
    phase3)
        phase3_core_services
        ;;
    phase4)
        phase4_critical_services
        ;;
    phase5)
        phase5_finalization
        ;;
    all)
        phase1_infrastructure
        phase2_pilot_services
        phase3_core_services
        phase4_critical_services
        phase5_finalization
        ;;
    *)
        echo "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: $0 {phase1|phase2|phase3|phase4|phase5|all} [namespace]"
        exit 1
        ;;
esac
```

### ğŸ“Š Production Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

#### 1. **SLI/SLO ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ**
```yaml
# production-slos.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: production-slos
  namespace: istio-system
spec:
  groups:
  - name: sli-slo.rules
    interval: 30s
    rules:
    # Availability SLI
    - record: sli:availability:rate5m
      expr: |
        sum(rate(istio_requests_total{response_code!~"5.*"}[5m])) by (destination_service_name, destination_namespace)
        /
        sum(rate(istio_requests_total[5m])) by (destination_service_name, destination_namespace)
    
    # Latency SLI
    - record: sli:latency:p99:5m
      expr: |
        histogram_quantile(0.99,
          sum(rate(istio_request_duration_milliseconds_bucket[5m])) by (destination_service_name, destination_namespace, le)
        )
    
    # Throughput SLI
    - record: sli:throughput:rate5m
      expr: |
        sum(rate(istio_requests_total[5m])) by (destination_service_name, destination_namespace)
    
    # Error Budget Alerts
    - alert: SLOAvailabilityBreach
      expr: |
        (
          sli:availability:rate5m < 0.999
        ) and (
          sli:availability:rate5m > 0
        )
      for: 2m
      labels:
        severity: critical
        slo: availability
      annotations:
        summary: "Service availability SLO breach"
        description: "Service {{ $labels.destination_service_name }} availability is {{ $value | humanizePercentage }}, below 99.9% SLO"
    
    - alert: SLOLatencyBreach
      expr: |
        sli:latency:p99:5m > 100
      for: 5m
      labels:
        severity: warning
        slo: latency
      annotations:
        summary: "Service latency SLO breach"
        description: "Service {{ $labels.destination_service_name }} P99 latency is {{ $value }}ms, above 100ms SLO"
    
    # Error Budget Burn Rate
    - alert: ErrorBudgetBurnRateHigh
      expr: |
        (
          1 - sli:availability:rate5m
        ) > (
          (1 - 0.999) * 14.4  # 14.4x burn rate for 2% budget in 1 hour
        )
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "High error budget burn rate"
        description: "Service {{ $labels.destination_service_name }} is burning error budget at {{ $value | humanizePercentage }} rate"
```

### ğŸ”’ Production security

#### 1. **Security hardening**
```yaml
# production-security.yaml

# Strict mTLS Ğ´Ğ»Ñ Ğ²ÑĞµĞ³Ğ¾ mesh
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: istio-system
spec:
  mtls:
    mode: STRICT
---
# Authorization policies
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-all
  namespace: production
spec:
  {}  # Deny all by default
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: production
spec:
  selector:
    matchLabels:
      app: backend-service
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/production/sa/frontend-service"]
  - to:
    - operation:
        methods: ["GET", "POST"]
        paths: ["/api/*"]
  - when:
    - key: source.ip
      values: ["10.0.0.0/8"]
---
# Network policies
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: istio-mesh-policy
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    - namespaceSelector:
        matchLabels:
          name: production
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    - namespaceSelector:
        matchLabels:
          name: production
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
---
# Security scanning
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: security-scanning
  namespace: production
spec:
  selector:
    matchLabels:
      security-scan: "enabled"
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/security/sa/scanner"]
  - to:
    - operation:
        methods: ["GET"]
        paths: ["/health", "/metrics"]
```

### ğŸ”§ ĞĞ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹

#### 1. **Disaster recovery Ğ¿Ğ»Ğ°Ğ½**
```bash
#!/bin/bash
# disaster-recovery.sh

echo "ğŸš¨ Service Mesh Disaster Recovery"

# Backup control plane
backup_control_plane() {
    echo "ğŸ’¾ Backup control plane ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸"
    
    local backup_dir="/backup/istio-$(date +%Y%m%d-%H%M%S)"
    mkdir -p $backup_dir
    
    # Backup Istio configuration
    kubectl get istiooperator -n istio-system -o yaml > $backup_dir/istio-operator.yaml
    kubectl get configmap istio -n istio-system -o yaml > $backup_dir/istio-config.yaml
    
    # Backup certificates
    kubectl get secret cacerts -n istio-system -o yaml > $backup_dir/cacerts.yaml
    
    # Backup custom resources
    kubectl get virtualservices --all-namespaces -o yaml > $backup_dir/virtualservices.yaml
    kubectl get destinationrules --all-namespaces -o yaml > $backup_dir/destinationrules.yaml
    kubectl get gateways --all-namespaces -o yaml > $backup_dir/gateways.yaml
    kubectl get peerauthentications --all-namespaces -o yaml > $backup_dir/peerauthentications.yaml
    kubectl get authorizationpolicies --all-namespaces -o yaml > $backup_dir/authorizationpolicies.yaml
    
    echo "âœ… Backup ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ² $backup_dir"
}

# Restore control plane
restore_control_plane() {
    local backup_dir=$1
    
    echo "ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ control plane Ğ¸Ğ· $backup_dir"
    
    # Restore certificates first
    kubectl apply -f $backup_dir/cacerts.yaml
    
    # Restore Istio operator
    kubectl apply -f $backup_dir/istio-operator.yaml
    
    # Wait for control plane
    kubectl wait --for=condition=available deployment/istiod -n istio-system --timeout=600s
    
    # Restore configuration
    kubectl apply -f $backup_dir/istio-config.yaml
    
    # Restore custom resources
    kubectl apply -f $backup_dir/virtualservices.yaml
    kubectl apply -f $backup_dir/destinationrules.yaml
    kubectl apply -f $backup_dir/gateways.yaml
    kubectl apply -f $backup_dir/peerauthentications.yaml
    kubectl apply -f $backup_dir/authorizationpolicies.yaml
    
    echo "âœ… Control plane Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½"
}

# Emergency procedures
emergency_procedures() {
    echo "ğŸš¨ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ emergency Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€"
    
    # Disable sidecar injection
    kubectl label namespace production istio-injection-
    
    # Remove problematic configurations
    kubectl delete virtualservices --all -n production
    kubectl delete destinationrules --all -n production
    
    # Restart workloads without sidecars
    kubectl rollout restart deployment --all -n production
    
    echo "âœ… Emergency Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹"
}

case "$1" in
    backup)
        backup_control_plane
        ;;
    restore)
        restore_control_plane $2
        ;;
    emergency)
        emergency_procedures
        ;;
    *)
        echo "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: $0 {backup|restore|emergency} [backup-dir]"
        exit 1
        ;;
esac
```

Service mesh Ğ² production Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğº Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ñƒ Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞµ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹.
