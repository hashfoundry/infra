# 164. ĞšĞ°Ğº Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ disaster recovery?

## ğŸ¯ **Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Disaster Recovery Ğ´Ğ»Ñ Kubernetes?**

**Disaster Recovery (DR) Ğ´Ğ»Ñ Kubernetes** â€” ÑÑ‚Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° Ğ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ°Ñ‚Ğ°ÑÑ‚Ñ€Ğ¾Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ±Ğ¾ĞµĞ², Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ°Ñ multi-region Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ failover, backup/restore Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹ Ğ¸ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… RTO Ğ¸ RPO.

## ğŸ—ï¸ **ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ DR ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸:**

### **1. Multi-Region Architecture (ĞœÑƒĞ»ÑŒÑ‚Ğ¸-Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°)**
- **Primary Cluster** - Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
- **Secondary Cluster** - Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğµ
- **Backup Storage** - Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ backup
- **DNS Failover** - Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ°

### **2. RTO/RPO Targets (Ğ¦ĞµĞ»Ğ¸ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ)**
- **RTO (Recovery Time Objective)** - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ
- **RPO (Recovery Point Objective)** - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- **Availability Targets** - Ñ†ĞµĞ»ĞµĞ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸
- **Service Tiers** - ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² Ğ¿Ğ¾ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸

### **3. Automation & Monitoring (ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³)**
- **Health Checks** - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
- **Automated Failover** - Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ
- **Alert Management** - ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸
- **Recovery Orchestration** - Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ

## ğŸ“Š **ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· Ğ²Ğ°ÑˆĞµĞ³Ğ¾ HA ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°:**

### **1. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ DR Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸:**
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
kubectl cluster-info
kubectl get nodes -o wide
kubectl get pods --all-namespaces --field-selector=status.phase!=Running

# ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
kubectl get pods -n kube-system -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° backup ÑĞ¸ÑÑ‚ĞµĞ¼
kubectl get pods -n velero
kubectl get backups -n velero --sort-by=.metadata.creationTimestamp

# ĞĞ½Ğ°Ğ»Ğ¸Ğ· persistent volumes
kubectl get pv -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,STORAGECLASS:.spec.storageClassName,SIZE:.spec.capacity.storage
```

### **2. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ DR Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:**
```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ etcd
kubectl get --raw /healthz/etcd

# ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
kubectl top nodes
kubectl top pods --all-namespaces --sort-by=cpu

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞµÑ‚ĞµĞ²Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ½Ğ¾ÑÑ‚Ğ¸
kubectl get svc -n ingress-nginx
kubectl get ingress --all-namespaces
```

### **3. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° backup Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸:**
```bash
# ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… backup
velero backup get --sort-by=.metadata.creationTimestamp
velero backup describe $(velero backup get -o name | tail -1)

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° backup locations
velero backup-location get
velero snapshot-location get

# ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° backup
kubectl get backups -n velero -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,SIZE:.status.totalItems,CREATED:.metadata.creationTimestamp
```

## ğŸ”„ **Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ DR ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸:**

### **1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Multi-Region DR Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹:**
```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ multi-region-dr-setup.sh
cat << 'EOF' > multi-region-dr-setup.sh
#!/bin/bash

echo "ğŸŒ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Multi-Region Disaster Recovery"
echo "=========================================="

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…
PRIMARY_CLUSTER="hashfoundry-ha"
DR_CLUSTER="hashfoundry-dr"
PRIMARY_REGION="fra1"
DR_REGION="ams3"
BACKUP_BUCKET="hashfoundry-backup"

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
check_dependencies() {
    log "ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹..."
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    for tool in kubectl doctl terraform helm; do
        if ! command -v $tool &> /dev/null; then
            log "âŒ $tool Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
            exit 1
        fi
    done
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
    if [ -z "$DO_TOKEN" ]; then
        log "âŒ DO_TOKEN Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½"
        exit 1
    fi
    
    log "âœ… Ğ’ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
create_dr_cluster() {
    log "ğŸ—ï¸ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Terraform ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ DR
    cat << TERRAFORM_EOF > dr-cluster.tf
# DR Cluster Configuration
resource "digitalocean_kubernetes_cluster" "dr_cluster" {
  name    = "$DR_CLUSTER"
  region  = "$DR_REGION"
  version = "1.31.9-do.2"
  
  node_pool {
    name       = "dr-worker-pool"
    size       = "s-2vcpu-4gb"
    node_count = 3
    
    auto_scale = true
    min_nodes  = 2
    max_nodes  = 8
    
    labels = {
      environment = "disaster-recovery"
      cluster     = "$DR_CLUSTER"
    }
    
    taint {
      key    = "disaster-recovery"
      value  = "true"
      effect = "NoSchedule"
    }
  }
  
  tags = ["disaster-recovery", "secondary", "ha"]
}

# VPC Ğ´Ğ»Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
resource "digitalocean_vpc" "dr_vpc" {
  name     = "$DR_CLUSTER-vpc"
  region   = "$DR_REGION"
  ip_range = "10.20.0.0/16"
  
  tags = ["disaster-recovery"]
}

# Load Balancer Ğ´Ğ»Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
resource "digitalocean_loadbalancer" "dr_lb" {
  name   = "$DR_CLUSTER-lb"
  region = "$DR_REGION"
  vpc_uuid = digitalocean_vpc.dr_vpc.id
  
  forwarding_rule {
    entry_protocol  = "https"
    entry_port      = 443
    target_protocol = "https"
    target_port     = 443
    tls_passthrough = true
  }
  
  forwarding_rule {
    entry_protocol  = "http"
    entry_port      = 80
    target_protocol = "http"
    target_port     = 80
  }
  
  healthcheck {
    protocol               = "http"
    port                   = 80
    path                   = "/healthz"
    check_interval_seconds = 10
    response_timeout_seconds = 5
    unhealthy_threshold    = 3
    healthy_threshold      = 2
  }
  
  tags = ["disaster-recovery"]
}

# Outputs
output "dr_cluster_id" {
  value = digitalocean_kubernetes_cluster.dr_cluster.id
}

output "dr_cluster_endpoint" {
  value = digitalocean_kubernetes_cluster.dr_cluster.endpoint
}

output "dr_lb_ip" {
  value = digitalocean_loadbalancer.dr_lb.ip
}
TERRAFORM_EOF
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Terraform ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
    terraform init
    terraform plan -var="do_token=$DO_TOKEN"
    terraform apply -auto-approve -var="do_token=$DO_TOKEN"
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ kubeconfig Ğ´Ğ»Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
    doctl kubernetes cluster kubeconfig save $DR_CLUSTER
    
    log "âœ… DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ ÑĞ¾Ğ·Ğ´Ğ°Ğ½"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
setup_dr_cluster() {
    log "âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$DR_REGION-$DR_CLUSTER
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ namespace Ğ´Ğ»Ñ DR
    kubectl create namespace disaster-recovery --dry-run=client -o yaml | kubectl apply -f -
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
    install_dr_components
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° tolerations Ğ´Ğ»Ñ DR ÑƒĞ·Ğ»Ğ¾Ğ²
    setup_dr_tolerations
    
    log "âœ… DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ DR ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
install_dr_components() {
    log "ğŸ“¦ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° DR ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²..."
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° NGINX Ingress
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    
    helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
        --namespace ingress-nginx \
        --create-namespace \
        --set controller.replicaCount=2 \
        --set controller.nodeSelector."kubernetes\.io/os"=linux \
        --set controller.tolerations[0].key=disaster-recovery \
        --set controller.tolerations[0].value=true \
        --set controller.tolerations[0].effect=NoSchedule \
        --set controller.service.type=LoadBalancer \
        --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-name"=$DR_CLUSTER-lb
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Velero Ğ´Ğ»Ñ DR
    install_velero_dr
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    install_monitoring_dr
    
    log "âœ… DR ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Velero Ğ´Ğ»Ñ DR
install_velero_dr() {
    log "ğŸ“¥ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Velero Ğ´Ğ»Ñ DR..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ credentials
    cat > /tmp/credentials-velero-dr << CRED_EOF
[default]
aws_access_key_id=${DO_SPACES_ACCESS_KEY}
aws_secret_access_key=${DO_SPACES_SECRET_KEY}
CRED_EOF
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Velero
    velero install \
        --provider aws \
        --plugins velero/velero-plugin-for-aws:v1.8.1,digitalocean/velero-plugin:v1.1.0 \
        --bucket $BACKUP_BUCKET \
        --secret-file /tmp/credentials-velero-dr \
        --backup-location-config region=$DR_REGION,s3ForcePathStyle="true",s3Url=https://$DR_REGION.digitaloceanspaces.com \
        --snapshot-location-config region=$DR_REGION \
        --use-volume-snapshots=true \
        --use-node-agent
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° tolerations Ğ´Ğ»Ñ Velero
    kubectl patch deployment velero -n velero -p '{"spec":{"template":{"spec":{"tolerations":[{"key":"disaster-recovery","value":"true","effect":"NoSchedule"}]}}}}'
    
    rm -f /tmp/credentials-velero-dr
    log "âœ… Velero Ğ´Ğ»Ñ DR ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ DR
install_monitoring_dr() {
    log "ğŸ“Š Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ DR..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ namespace
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Prometheus Ğ´Ğ»Ñ DR
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    
    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --set prometheus.prometheusSpec.nodeSelector."kubernetes\.io/os"=linux \
        --set prometheus.prometheusSpec.tolerations[0].key=disaster-recovery \
        --set prometheus.prometheusSpec.tolerations[0].value=true \
        --set prometheus.prometheusSpec.tolerations[0].effect=NoSchedule \
        --set grafana.nodeSelector."kubernetes\.io/os"=linux \
        --set grafana.tolerations[0].key=disaster-recovery \
        --set grafana.tolerations[0].value=true \
        --set grafana.tolerations[0].effect=NoSchedule \
        --set prometheus.prometheusSpec.retention=7d \
        --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=do-block-storage \
        --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi
    
    log "âœ… ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ DR ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ tolerations
setup_dr_tolerations() {
    log "ğŸ”§ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° tolerations Ğ´Ğ»Ñ DR..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DaemonSet Ğ´Ğ»Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑƒĞ·Ğ»Ğ¾Ğ²
    cat << DAEMONSET_EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: dr-node-setup
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: dr-node-setup
  template:
    metadata:
      labels:
        name: dr-node-setup
    spec:
      tolerations:
      - key: disaster-recovery
        value: "true"
        effect: NoSchedule
      hostNetwork: true
      hostPID: true
      containers:
      - name: node-setup
        image: alpine:latest
        command: ["/bin/sh"]
        args: ["-c", "while true; do sleep 3600; done"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: host-root
          mountPath: /host
      volumes:
      - name: host-root
        hostPath:
          path: /
      nodeSelector:
        kubernetes.io/os: linux
DAEMONSET_EOF
    
    log "âœ… Tolerations Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ DNS failover
setup_dns_failover() {
    log "ğŸŒ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° DNS failover..."
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ IP Ğ°Ğ´Ñ€ĞµÑĞ¾Ğ²
    PRIMARY_LB_IP=$(kubectl config use-context do-$PRIMARY_REGION-$PRIMARY_CLUSTER && kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    DR_LB_IP=$(kubectl config use-context do-$DR_REGION-$DR_CLUSTER && kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DNS Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
    doctl compute domain records create hashfoundry.com \
        --record-type A \
        --record-name api \
        --record-data $PRIMARY_LB_IP \
        --record-ttl 300 \
        --record-priority 10
    
    doctl compute domain records create hashfoundry.com \
        --record-type A \
        --record-name api-dr \
        --record-data $DR_LB_IP \
        --record-ttl 300
    
    log "âœ… DNS failover Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½"
    log "Primary: api.hashfoundry.com -> $PRIMARY_LB_IP"
    log "DR: api-dr.hashfoundry.com -> $DR_LB_IP"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ DR
test_dr_setup() {
    log "ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸..."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$DR_REGION-$DR_CLUSTER
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒĞ·Ğ»Ğ¾Ğ²
    kubectl get nodes -o wide
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾Ğ´Ğ¾Ğ²
    kubectl get pods --all-namespaces
    
    # Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ
    kubectl run dr-test --image=nginx:alpine --port=80
    kubectl expose pod dr-test --type=LoadBalancer --port=80
    
    # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ IP
    log "â³ ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ IP..."
    kubectl wait --for=condition=ready pod/dr-test --timeout=300s
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ IP
    EXTERNAL_IP=$(kubectl get svc dr-test -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    log "ğŸŒ Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: http://$EXTERNAL_IP"
    
    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
    kubectl delete pod dr-test
    kubectl delete svc dr-test
    
    log "âœ… DR Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾"
}

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
main() {
    log "ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Multi-Region DR"
    
    check_dependencies
    create_dr_cluster
    setup_dr_cluster
    setup_dns_failover
    test_dr_setup
    
    log "ğŸ‰ MULTI-REGION DR Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ ĞĞĞ¡Ğ¢Ğ ĞĞ•Ğ!"
    log "ğŸ“‹ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:"
    log "  1. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ failover"
    log "  2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ DR runbooks"
    log "  3. ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ DR drill"
    log "  4. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ DR Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº"
}

# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
trap 'log "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞµ DR"; exit 1' ERR

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
main "$@"
EOF

chmod +x multi-region-dr-setup.sh
```

### **2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ failover:**
```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ automated-failover.sh
cat << 'EOF' > automated-failover.sh
#!/bin/bash

echo "ğŸš¨ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Disaster Recovery Failover"
echo "=============================================="

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…
PRIMARY_CLUSTER="hashfoundry-ha"
DR_CLUSTER="hashfoundry-dr"
PRIMARY_REGION="fra1"
DR_REGION="ams3"
DOMAIN="hashfoundry.com"
SLACK_WEBHOOK="$SLACK_WEBHOOK_URL"

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
send_notification() {
    local severity="$1"
    local message="$2"
    
    log "$severity $message"
    
    # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        local color="good"
        case $severity in
            "ğŸš¨") color="danger" ;;
            "âš ï¸") color="warning" ;;
            "âœ…") color="good" ;;
        esac
        
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"attachments\":[{\"color\":\"$color\",\"text\":\"$severity DR Alert: $message\",\"ts\":$(date +%s)}]}" \
            "$SLACK_WEBHOOK" >/dev/null 2>&1
    fi
    
    # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² Prometheus
    if [ -n "$PROMETHEUS_PUSHGATEWAY" ]; then
        echo "dr_failover_event{severity=\"$severity\",message=\"$message\"} 1" | \
            curl --data-binary @- "$PROMETHEUS_PUSHGATEWAY/metrics/job/dr_failover" >/dev/null 2>&1
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
check_primary_health() {
    log "ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$PRIMARY_REGION-$PRIMARY_CLUSTER >/dev/null 2>&1
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° API server
    if ! timeout 30 kubectl cluster-info >/dev/null 2>&1; then
        log "âŒ Primary API server Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° etcd
    if ! timeout 15 kubectl get --raw /healthz/etcd >/dev/null 2>&1; then
        log "âŒ etcd Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¾Ğ²
    local failed_pods=$(kubectl get pods -n kube-system --field-selector=status.phase!=Running --no-headers 2>/dev/null | wc -l)
    if [ "$failed_pods" -gt 5 ]; then
        log "âŒ Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ½ĞµÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ñ… ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¾Ğ²: $failed_pods"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒĞ·Ğ»Ğ¾Ğ²
    local not_ready_nodes=$(kubectl get nodes --no-headers 2>/dev/null | grep -v Ready | wc -l)
    if [ "$not_ready_nodes" -gt 1 ]; then
        log "âŒ Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ½ĞµĞ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ñ… ÑƒĞ·Ğ»Ğ¾Ğ²: $not_ready_nodes"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ingress controller
    if ! kubectl get pods -n ingress-nginx -l app.kubernetes.io/name=ingress-nginx --field-selector=status.phase=Running >/dev/null 2>&1; then
        log "âŒ Ingress controller Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        return 1
    fi
    
    log "âœ… Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²"
    return 0
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
check_dr_health() {
    log "ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$DR_REGION-$DR_CLUSTER >/dev/null 2>&1
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° API server
    if ! timeout 30 kubectl cluster-info >/dev/null 2>&1; then
        log "âŒ DR API server Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        return 1
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒĞ·Ğ»Ğ¾Ğ²
    local ready_nodes=$(kubectl get nodes --no-headers 2>/dev/null | grep Ready | wc -l)
    if [ "$ready_nodes" -lt 2 ]; then
        log "âŒ ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ñ… ÑƒĞ·Ğ»Ğ¾Ğ² Ğ² DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğµ: $ready_nodes"
        return 1
    fi
    
    log "âœ… DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº failover"
    return 0
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ emergency backup
create_emergency_backup() {
    log "ğŸ’¾ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ emergency backup..."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$PRIMARY_REGION-$PRIMARY_CLUSTER >/dev/null 2>&1
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ emergency backup Ñ‡ĞµÑ€ĞµĞ· Velero
    local backup_name="emergency-backup-$(date +%Y%m%d-%H%M%S)"
    
    if timeout 300 velero backup create $backup_name \
        --include-namespaces argocd,monitoring,default \
        --wait >/dev/null 2>&1; then
        log "âœ… Emergency backup ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $backup_name"
        echo $backup_name
    else
        log "âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ emergency backup"
        echo ""
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ñ†Ğ¸Ğ¸ failover
initiate_failover() {
    log "ğŸš¨ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ñ†Ğ¸Ñ failover Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€..."
    
    send_notification "ğŸš¨" "Primary cluster failure detected. Initiating failover to DR cluster."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ emergency backup (ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾)
    local backup_name=$(create_emergency_backup)
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-$DR_REGION-$DR_CLUSTER
    
    # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
    scale_dr_cluster
    
    # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· backup
    if [ -n "$backup_name" ]; then
        restore_from_backup "$backup_name"
    else
        restore_from_latest_backup
    fi
    
    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ DNS Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
    update_dns_records
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
    deploy_critical_services
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸
    verify_dr_services
    
    send_notification "âœ…" "Failover completed successfully. Services are running on DR cluster."
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
scale_dr_cluster() {
    log "ğŸ“ˆ ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    # Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° ÑƒĞ·Ğ»Ğ¾Ğ²
    doctl kubernetes cluster node-pool update $DR_CLUSTER dr-worker-pool \
        --count 6 \
        --auto-scale \
        --min-nodes 3 \
        --max-nodes 12 >/dev/null 2>&1
    
    # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ ÑƒĞ·Ğ»Ğ¾Ğ²
    log "â³ ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ ÑƒĞ·Ğ»Ğ¾Ğ²..."
    for i in {1..30}; do
        local ready_nodes=$(kubectl get nodes --no-headers | grep Ready | wc -l)
        if [ "$ready_nodes" -ge 4 ]; then
            log "âœ… DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: $ready_nodes ÑƒĞ·Ğ»Ğ¾Ğ² Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾"
            break
        fi
        sleep 10
    done
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ· backup
restore_from_backup() {
    local backup_name="$1"
    log "ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· backup: $backup_name"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ restore
    local restore_name="dr-restore-$(date +%s)"
    velero restore create $restore_name --from-backup $backup_name >/dev/null 2>&1
    
    # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ restore
    log "â³ ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ restore..."
    for i in {1..60}; do
        local status=$(velero restore get $restore_name -o json 2>/dev/null | jq -r '.status.phase' 2>/dev/null)
        if [ "$status" = "Completed" ]; then
            log "âœ… Restore Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾"
            return 0
        elif [ "$status" = "Failed" ]; then
            log "âŒ Restore Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ»ÑÑ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹"
            return 1
        fi
        sleep 10
    done
    
    log "âš ï¸ Restore Ğ½Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ»ÑÑ Ğ² Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ"
    return 1
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ backup
restore_from_latest_backup() {
    log "ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ backup..."
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ backup
    local latest_backup=$(velero backup get -o json 2>/dev/null | jq -r '.items | sort_by(.metadata.creationTimestamp) | last | .metadata.name' 2>/dev/null)
    
    if [ "$latest_backup" != "null" ] && [ -n "$latest_backup" ]; then
        restore_from_backup "$latest_backup"
    else
        log "âš ï¸ Backup Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ÑƒĞ»Ñ"
        deploy_from_scratch
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ DNS Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
update_dns_records() {
    log "ğŸŒ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ DNS Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹..."
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ IP DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
    local dr_external_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
    
    if [ -n "$dr_external_ip" ]; then
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ A Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ°
        doctl compute domain records update $DOMAIN \
            --record-type A \
            --record-name api \
            --record-data $dr_external_ip \
            --record-ttl 60 >/dev/null 2>&1
        
        log "âœ… DNS Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: api.$DOMAIN -> $dr_external_ip"
    else
        log "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ IP DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°"
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
deploy_critical_services() {
    log "ğŸš€ Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²..."
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ArgoCD
    deploy_argocd_dr
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    deploy_monitoring_dr
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
    deploy_applications_dr
    
    log "âœ… ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ ArgoCD Ğ´Ğ»Ñ DR
deploy_argocd_dr() {
    log "ğŸ“¦ Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ ArgoCD Ğ´Ğ»Ñ DR..."
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ namespace
    kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
    
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ArgoCD
    kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml >/dev/null 2>&1
    
    # ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s >/dev/null 2>&1
    
    log "âœ… ArgoCD Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ DR
deploy_monitoring_dr() {
    log "ğŸ“Š Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ DR..."
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    if kubectl get namespace monitoring >/dev/null 2>&1; then
        log "âœ… ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ ÑƒĞ¶Ğµ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚"
        return 0
    fi
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ namespace
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
    
    # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Prometheus
    kubectl apply -f - << PROMETHEUS_EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      tolerations:
      - key: disaster-recovery
        value: "true"
        effect: NoSchedule
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
PROMETHEUS_EOF
    
    log "âœ… ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ DR Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ DR
deploy_applications_dr() {
    log "ğŸš€ Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ DR..."
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    kubectl apply -f - << APP_EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hashfoundry-app
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hashfoundry-app
  template:
    metadata:
      labels:
        app: hashfoundry-app
    spec:
      tolerations:
      - key: disaster-recovery
        value: "true"
        effect: NoSchedule
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi
---
apiVersion: v1
kind: Service
metadata:
  name: hashfoundry-app
  namespace: default
spec:
  selector:
    app: hashfoundry-app
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
APP_EOF
    
    log "âœ… ĞŸÑ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ DR Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ½ÑƒĞ»Ñ
deploy_from_scratch() {
    log "ğŸ—ï¸ Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ÑƒĞ»Ñ..."
    
    # Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
    deploy_critical_services
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
    kubectl apply -f - << CONFIG_EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: dr-config
  namespace: default
data:
  environment: "disaster-recovery"
  cluster: "$DR_CLUSTER"
  region: "$DR_REGION"
  deployment_time: "$(date)"
CONFIG_EOF
    
    log "âœ… Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ½ÑƒĞ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ DR ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
verify_dr_services() {
    log "âœ… ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ DR ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²..."
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒĞ·Ğ»Ğ¾Ğ²
    local ready_nodes=$(kubectl get nodes --no-headers | grep Ready | wc -l)
    log "Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ñ… ÑƒĞ·Ğ»Ğ¾Ğ²: $ready_nodes"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¾Ğ²
    log "ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ñ‹:"
    kubectl get pods -n kube-system --field-selector=status.phase=Running
    kubectl get pods -n ingress-nginx --field-selector=status.phase=Running
    
    # Ğ¢ĞµÑÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
    test_service_availability
    
    log "âœ… DR ÑĞµÑ€Ğ²Ğ¸ÑÑ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
test_service_availability() {
    log "ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²..."
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ IP
    local external_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
    
    if [ -n "$external_ip" ]; then
        log "ğŸŒ Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ IP DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°: $external_ip"
        
        # Ğ¢ĞµÑÑ‚ HTTP Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸
        if curl -f -s "http://$external_ip" >/dev/null 2>&1; then
            log "âœ… HTTP Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ°"
        else
            log "âš ï¸ HTTP Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        fi
    else
        log "âš ï¸ Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğ¹ IP Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½"
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° DR
monitor_dr_health() {
    log "ğŸ“Š Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° DR..."
    
    while true; do
        if ! check_primary_health; then
            log "ğŸš¨ Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½!"
            
            if check_dr_health; then
                log "ğŸš¨ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ñ†Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ failover..."
                initiate_failover
                break
            else
                log "âŒ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½!"
                send_notification "ğŸš¨" "Both primary and DR clusters are unavailable!"
            fi
        else
            log "âœ… Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾"
        fi
        
        sleep 60  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ°Ğ¶Ğ´ÑƒÑ Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
    done
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
restore_primary_cluster() {
    log "ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
    
    send_notification "ğŸ”„" "Starting primary cluster recovery process."
    
    # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ½Ğ° primary
    kubectl config use-context do-$PRIMARY_REGION-$PRIMARY_CLUSTER
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ primary
    if check_primary_health; then
        log "âœ… Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½"
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ backup Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ DR
        create_dr_backup
        
        # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ DNS Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾
        switch_dns_to_primary
        
        # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾
        scale_down_dr_cluster
        
        send_notification "âœ…" "Primary cluster recovery completed. Traffic switched back."
    else
        log "âŒ Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ²ÑĞµ ĞµÑ‰Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
        send_notification "âš ï¸" "Primary cluster recovery failed. Continuing on DR cluster."
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ backup DR ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
create_dr_backup() {
    log "ğŸ’¾ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ backup DR ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ..."
    
    kubectl config use-context do-$DR_REGION-$DR_CLUSTER
    
    local dr_backup_name="dr-state-backup-$(date +%Y%m%d-%H%M%S)"
    velero backup create $dr_backup_name \
        --include-namespaces default,monitoring,argocd \
        --wait >/dev/null 2>&1
    
    log "âœ… DR backup ÑĞ¾Ğ·Ğ´Ğ°Ğ½: $dr_backup_name"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ DNS Ğ½Ğ° primary
switch_dns_to_primary() {
    log "ğŸŒ ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ DNS Ğ½Ğ° primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€..."
    
    kubectl config use-context do-$PRIMARY_REGION-$PRIMARY_CLUSTER
    local primary_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
    
    if [ -n "$primary_ip" ]; then
        doctl compute domain records update $DOMAIN \
            --record-type A \
            --record-name api \
            --record-data $primary_ip \
            --record-ttl 300 >/dev/null 2>&1
        
        log "âœ… DNS Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½ Ğ½Ğ° primary: api.$DOMAIN -> $primary_ip"
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° Ğ²Ğ½Ğ¸Ğ·
scale_down_dr_cluster() {
    log "ğŸ“‰ ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° Ğ²Ğ½Ğ¸Ğ·..."
    
    doctl kubernetes cluster node-pool update $DR_CLUSTER dr-worker-pool \
        --count 2 \
        --auto-scale \
        --min-nodes 2 \
        --max-nodes 4 >/dev/null 2>&1
    
    log "âœ… DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ²Ğ½Ğ¸Ğ·"
}

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
main() {
    case "$1" in
        monitor)
            log "ğŸ” Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° DR..."
            monitor_dr_health
            ;;
        failover)
            log "ğŸš¨ ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ failover..."
            if check_dr_health; then
                initiate_failover
            else
                log "âŒ DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ´Ğ»Ñ failover"
                exit 1
            fi
            ;;
        restore)
            log "ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°..."
            restore_primary_cluster
            ;;
        test)
            log "ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸..."
            check_primary_health
            check_dr_health
            verify_dr_services
            ;;
        *)
            echo "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: $0 {monitor|failover|restore|test}"
            echo "  monitor  - ĞĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ failover"
            echo "  failover - ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ failover Ğ½Ğ° DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€"
            echo "  restore  - Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°"
            echo "  test     - Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸"
            exit 1
            ;;
    esac
}

# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
trap 'send_notification "âŒ" "DR script error occurred"; exit 1' ERR

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
main "$@"
EOF

chmod +x automated-failover.sh
```

## ğŸ“Š **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Disaster Recovery:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Multi-Region DR Architecture                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Primary Region (fra1)          DR Region (ams3)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Primary Cluster    â”‚        â”‚   DR Cluster        â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Control Plane  â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”œâ”€â”€ Control Plane  â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Worker Nodes   â”‚        â”‚  â”œâ”€â”€ Worker Nodes   â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ArgoCD         â”‚        â”‚  â”œâ”€â”€ ArgoCD (Sync)  â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Monitoring     â”‚        â”‚  â”œâ”€â”€ Monitoring     â”‚     â”‚
â”‚  â”‚  â””â”€â”€ Applications   â”‚        â”‚  â””â”€â”€ Applications   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                              â”‚                  â”‚
â”‚           â–¼                              â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Load Balancer     â”‚        â”‚   Load Balancer     â”‚     â”‚
â”‚  â”‚   (Primary LB)      â”‚        â”‚   (DR LB)           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                              â”‚                  â”‚
â”‚           â–¼                              â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              DNS Failover Management                    â”‚ â”‚
â”‚  â”‚  api.hashfoundry.com â†’ Primary LB (Normal)             â”‚ â”‚
â”‚  â”‚  api.hashfoundry.com â†’ DR LB (Failover)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Shared Components                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Backup Storage (Digital Ocean Spaces)                 â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ etcd snapshots                                    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Application data                                  â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Configuration backups                             â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Volume snapshots                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Monitoring & Alerting                                 â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Health checks                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Automated failover triggers                       â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Slack/Teams notifications                         â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Prometheus metrics                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ **ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ğ° DR ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹:**

### **1. RTO/RPO Ñ†ĞµĞ»Ğ¸ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²:**
| Tier | Ğ¡ĞµÑ€Ğ²Ğ¸ÑÑ‹ | RTO | RPO | Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ |
|------|---------|-----|-----|-----------|-----------|
| Tier 1 | API, Auth, etcd | < 15 Ğ¼Ğ¸Ğ½ | < 5 Ğ¼Ğ¸Ğ½ | Hot Standby | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ |
| Tier 2 | Web App, Monitoring | < 1 Ñ‡Ğ°Ñ | < 30 Ğ¼Ğ¸Ğ½ | Warm Standby | Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ |
| Tier 3 | Analytics, Reports | < 4 Ñ‡Ğ°ÑĞ° | < 4 Ñ‡Ğ°ÑĞ° | Cold Standby | ĞĞ¸Ğ·ĞºĞ°Ñ |

### **2. ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° DR:**
```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ dr-monitoring.sh
cat << 'EOF' > dr-monitoring.sh
#!/bin/bash

echo "ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ DR Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸"
echo "=========================="

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ DR Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
check_dr_metrics() {
    echo "ğŸ” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° DR Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… backup
    echo "ğŸ“¦ ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ backup:"
    velero backup get --sort-by=.metadata.creationTimestamp | tail -5
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²
    echo -e "\nğŸ—ï¸ Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²:"
    
    # Primary ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-fra1-hashfoundry-ha >/dev/null 2>&1
    PRIMARY_NODES=$(kubectl get nodes --no-headers | grep Ready | wc -l)
    PRIMARY_PODS=$(kubectl get pods --all-namespaces --field-selector=status.phase=Running --no-headers | wc -l)
    echo "Primary: $PRIMARY_NODES ÑƒĞ·Ğ»Ğ¾Ğ², $PRIMARY_PODS Ğ¿Ğ¾Ğ´Ğ¾Ğ²"
    
    # DR ĞºĞ»Ğ°ÑÑ‚ĞµÑ€
    kubectl config use-context do-ams3-hashfoundry-dr >/dev/null 2>&1
    DR_NODES=$(kubectl get nodes --no-headers | grep Ready | wc -l)
    DR_PODS=$(kubectl get pods --all-namespaces --field-selector=status.phase=Running --no-headers | wc -l)
    echo "DR: $DR_NODES ÑƒĞ·Ğ»Ğ¾Ğ², $DR_PODS Ğ¿Ğ¾Ğ´Ğ¾Ğ²"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° backup Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ğ°
    echo -e "\nâ° Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ backup:"
    LATEST_BACKUP=$(velero backup get -o json | jq -r '.items | sort_by(.metadata.creationTimestamp) | last | .metadata.creationTimestamp')
    if [ "$LATEST_BACKUP" != "null" ]; then
        BACKUP_AGE=$(( $(date +%s) - $(date -d "$LATEST_BACKUP" +%s) ))
        BACKUP_AGE_MIN=$((BACKUP_AGE / 60))
        echo "ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ backup: $BACKUP_AGE_MIN Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ½Ğ°Ğ·Ğ°Ğ´"
        
        if [ $BACKUP_AGE -gt 3600 ]; then
            echo "âš ï¸ WARNING: Backup ÑÑ‚Ğ°Ñ€ÑˆĞµ 1 Ñ‡Ğ°ÑĞ°"
        else
            echo "âœ… Backup Ğ°ĞºÑ‚ÑƒĞ°Ğ»ĞµĞ½"
        fi
    else
        echo "âŒ Backup Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½"
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ DNS ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
check_dns_config() {
    echo -e "\nğŸŒ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° DNS ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸:"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… DNS Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
    API_IP=$(dig +short api.hashfoundry.com)
    echo "api.hashfoundry.com -> $API_IP"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸
    if curl -f -s "http://$API_IP" >/dev/null 2>&1; then
        echo "âœ… API Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
    else
        echo "âŒ API Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½"
    fi
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
check_automation() {
    echo -e "\nğŸ¤– ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° CronJob Ğ´Ğ»Ñ backup
    BACKUP_JOBS=$(kubectl get cronjobs --all-namespaces --no-headers | grep backup | wc -l)
    echo "Backup CronJobs: $BACKUP_JOBS"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    MONITORING_PODS=$(kubectl get pods -n monitoring --field-selector=status.phase=Running --no-headers | wc -l)
    echo "ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾Ğ´Ğ¾Ğ²: $MONITORING_PODS"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ°Ğ»ĞµÑ€Ñ‚Ğ¾Ğ²
    if kubectl get prometheusrules -n monitoring disaster-recovery-alerts >/dev/null 2>&1; then
        echo "âœ… DR Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹"
    else
        echo "âš ï¸ DR Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹"
    fi
}

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
main() {
    echo "ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš DR ĞœĞĞĞ˜Ğ¢ĞĞ Ğ˜ĞĞ“Ğ"
    echo "======================="
    
    check_dr_metrics
    check_dns_config
    check_automation
    
    echo -e "\nğŸ’¡ Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ˜:"
    echo "1. Ğ ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ DR Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹"
    echo "2. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞ¹Ñ‚Ğµ DR runbooks"
    echo "3. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ÑŒÑ‚Ğµ RTO/RPO Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸"
    echo "4. ĞŸÑ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚Ğµ DR drills ĞµĞ¶ĞµĞ¼ĞµÑÑÑ‡Ğ½Ğ¾"
    
    echo -e "\nâœ… DR ĞœĞĞĞ˜Ğ¢ĞĞ Ğ˜ĞĞ“ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ!"
}

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
main
EOF

chmod +x dr-monitoring.sh
```

## ğŸ¯ **Best Practices Ğ´Ğ»Ñ Disaster Recovery:**

### **1. ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR**
- ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² Ğ¸ RTO/RPO Ñ†ĞµĞ»Ğ¸
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ multi-region Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ
- ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ backup
- Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹Ñ‚Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ runbooks

### **2. ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ DR**
- ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ health monitoring
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞ¹Ñ‚Ğµ automated failover
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ DNS failover Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹
- Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹

### **3. Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ DR**
- ĞŸÑ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ DR drills
- Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ restore Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞ¹Ñ‚Ğµ RTO/RPO ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ
- Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ¾Ğ²

### **4. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ**
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ¹Ñ‚Ğµ DR Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
- ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¸Ğ½Ñ†Ğ¸Ğ´ĞµĞ½Ñ‚Ñ‹
- ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹
- ĞĞ±ÑƒÑ‡Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ

**Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Disaster Recovery Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ°Ñ‚Ğ°ÑÑ‚Ñ€Ğ¾Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ±Ğ¾ĞµĞ² Ğ¸ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ½Ğ° Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹!**
