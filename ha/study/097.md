# 97. Cluster Autoscaler

## üéØ **Cluster Autoscaler**

**Cluster Autoscaler** - —ç—Ç–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç Kubernetes, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞, –¥–æ–±–∞–≤–ª—è—è –∏–ª–∏ —É–¥–∞–ª—è—è —É–∑–ª—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –≤ —Ä–µ—Å—É—Ä—Å–∞—Ö. –û–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –æ–±–ª–∞—á–Ω—ã–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è node pools –∫–æ–≥–¥–∞ Pod'—ã –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã –∏–∑-–∑–∞ –Ω–µ—Ö–≤–∞—Ç–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.

## üèóÔ∏è **–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Cluster Autoscaler:**

### **1. Core Components:**
- **Cluster Autoscaler Pod** - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä
- **Cloud Provider Integration** - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –æ–±–ª–∞—á–Ω—ã–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º
- **Node Group Management** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏ —É–∑–ª–æ–≤
- **Scaling Policies** - –ø–æ–ª–∏—Ç–∏–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è

### **2. Scaling Logic:**
- **Scale Up** - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ —Ä–µ—Å—É—Ä—Å–æ–≤
- **Scale Down** - —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —É–∑–ª–æ–≤
- **Node Utilization** - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–∑–ª–æ–≤
- **Pod Scheduling** - –∞–Ω–∞–ª–∏–∑ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è Pod'–æ–≤

## üìä **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –≤–∞—à–µ–≥–æ HA –∫–ª–∞—Å—Ç–µ—Ä–∞:**

### **1. –ê–Ω–∞–ª–∏–∑ Cluster Autoscaler –≤ DigitalOcean:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤ .env
grep -E "(AUTO_SCALE|MIN_NODES|MAX_NODES)" ha/.env

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Cluster Autoscaler –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
kubectl get pods -n kube-system | grep cluster-autoscaler
kubectl describe configmap cluster-autoscaler-status -n kube-system
```

### **2. –°–æ–∑–¥–∞–Ω–∏–µ comprehensive Cluster Autoscaler toolkit:**
```bash
# –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Cluster Autoscaler
cat << 'EOF' > kubernetes-cluster-autoscaler-toolkit.sh
#!/bin/bash

echo "=== Kubernetes Cluster Autoscaler Toolkit ==="
echo "Comprehensive toolkit for Cluster Autoscaler in HashFoundry HA cluster"
echo

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è Cluster Autoscaler
analyze_cluster_autoscaler() {
    echo "=== Cluster Autoscaler Analysis ==="
    
    echo "1. Cluster Autoscaler Pod Status:"
    echo "================================="
    kubectl get pods -n kube-system -l app=cluster-autoscaler -o custom-columns="NAME:.metadata.name,STATUS:.status.phase,READY:.status.conditions[?(@.type=='Ready')].status,NODE:.spec.nodeName,AGE:.metadata.creationTimestamp"
    echo
    
    echo "2. Cluster Autoscaler Configuration:"
    echo "==================================="
    kubectl get deployment cluster-autoscaler -n kube-system -o jsonpath='{.spec.template.spec.containers[0].command}' 2>/dev/null | jq -r '.[]' | grep -E "(min-nodes|max-nodes|scale-down)" || echo "Cluster Autoscaler deployment not found"
    echo
    
    echo "3. Node Groups and Scaling Limits:"
    echo "=================================="
    kubectl get nodes -o custom-columns="NAME:.metadata.name,INSTANCE-TYPE:.metadata.labels.node\.kubernetes\.io/instance-type,ZONE:.metadata.labels.topology\.kubernetes\.io/zone,UNSCHEDULABLE:.spec.unschedulable,AGE:.metadata.creationTimestamp"
    echo
    
    echo "4. Cluster Autoscaler Status ConfigMap:"
    echo "======================================="
    kubectl get configmap cluster-autoscaler-status -n kube-system -o jsonpath='{.data}' 2>/dev/null | jq . || echo "Status ConfigMap not found"
    echo
    
    echo "5. Recent Scaling Events:"
    echo "========================"
    kubectl get events -n kube-system --field-selector source=cluster-autoscaler --sort-by='.lastTimestamp' | tail -10 || echo "No cluster autoscaler events found"
    echo
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∞
monitor_cluster_resources() {
    echo "=== Cluster Resource Monitoring ==="
    
    echo "1. Node Resource Allocation:"
    echo "==========================="
    kubectl describe nodes | grep -A 5 "Allocated resources:" | grep -E "(Resource|cpu|memory|Requests|Limits)" || echo "Resource information not available"
    echo
    
    echo "2. Pending Pods (trigger for scale up):"
    echo "======================================="
    kubectl get pods --all-namespaces --field-selector=status.phase=Pending -o custom-columns="NAMESPACE:.metadata.namespace,NAME:.metadata.name,REASON:.status.conditions[?(@.type=='PodScheduled')].reason,MESSAGE:.status.conditions[?(@.type=='PodScheduled')].message"
    echo
    
    echo "3. Node Utilization:"
    echo "==================="
    kubectl top nodes 2>/dev/null || echo "Metrics server not available"
    echo
    
    echo "4. Unschedulable Nodes:"
    echo "======================"
    kubectl get nodes --field-selector spec.unschedulable=true -o custom-columns="NAME:.metadata.name,REASON:.metadata.annotations.cluster-autoscaler\.kubernetes\.io/scale-down-disabled,SINCE:.metadata.creationTimestamp"
    echo
    
    echo "5. Node Pool Information (DigitalOcean):"
    echo "========================================"
    # This would require doctl CLI tool
    if command -v doctl >/dev/null 2>&1; then
        doctl kubernetes cluster node-pool list hashfoundry-ha 2>/dev/null || echo "doctl not configured or cluster not found"
    else
        echo "doctl CLI not available - install with: snap install doctl"
    fi
    echo
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è test workloads –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
create_scaling_test_workloads() {
    echo "=== Creating Scaling Test Workloads ==="
    
    # –°–æ–∑–¥–∞—Ç—å namespace –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    kubectl create namespace cluster-autoscaler-test --dry-run=client -o yaml | kubectl apply -f -
    
    # Test 1: Resource-intensive workload to trigger scale up
    cat << SCALE_UP_TEST_EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-intensive-scale-test
  namespace: cluster-autoscaler-test
  labels:
    app.kubernetes.io/name: "resource-intensive-scale-test"
    hashfoundry.io/test: "cluster-autoscaler-scale-up"
  annotations:
    hashfoundry.io/description: "Resource intensive workload to test cluster scale up"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: "resource-intensive-scale-test"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "resource-intensive-scale-test"
        hashfoundry.io/test-type: "scale-up"
    spec:
      containers:
      - name: resource-consumer
        image: nginx:1.21-alpine
        resources:
          requests:
            cpu: "1500m"  # High CPU request to trigger scaling
            memory: "2Gi"  # High memory request
          limits:
            cpu: "2"
            memory: "4Gi"
        ports:
        - containerPort: 80
        env:
        - name: TEST_TYPE
          value: "cluster-autoscaler-scale-up"
SCALE_UP_TEST_EOF
    
    # Test 2: Multiple small workloads
    cat << MULTIPLE_PODS_TEST_EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multiple-pods-scale-test
  namespace: cluster-autoscaler-test
  labels:
    app.kubernetes.io/name: "multiple-pods-scale-test"
    hashfoundry.io/test: "cluster-autoscaler-multiple-pods"
  annotations:
    hashfoundry.io/description: "Multiple pods to test cluster scaling behavior"
spec:
  replicas: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: "multiple-pods-scale-test"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "multiple-pods-scale-test"
        hashfoundry.io/test-type: "multiple-pods"
    spec:
      containers:
      - name: pod
        image: nginx:1.21-alpine
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "1Gi"
        ports:
        - containerPort: 80
        env:
        - name: TEST_TYPE
          value: "cluster-autoscaler-multiple-pods"
MULTIPLE_PODS_TEST_EOF
    
    # Test 3: Anti-affinity workload to force node spreading
    cat << ANTI_AFFINITY_TEST_EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: anti-affinity-scale-test
  namespace: cluster-autoscaler-test
  labels:
    app.kubernetes.io/name: "anti-affinity-scale-test"
    hashfoundry.io/test: "cluster-autoscaler-anti-affinity"
  annotations:
    hashfoundry.io/description: "Anti-affinity workload to force node spreading"
spec:
  replicas: 5
  selector:
    matchLabels:
      app.kubernetes.io/name: "anti-affinity-scale-test"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "anti-affinity-scale-test"
        hashfoundry.io/test-type: "anti-affinity"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - anti-affinity-scale-test
            topologyKey: kubernetes.io/hostname
      containers:
      - name: pod
        image: nginx:1.21-alpine
        resources:
          requests:
            cpu: "800m"
            memory: "1Gi"
          limits:
            cpu: "1"
            memory: "2Gi"
        ports:
        - containerPort: 80
        env:
        - name: TEST_TYPE
          value: "cluster-autoscaler-anti-affinity"
ANTI_AFFINITY_TEST_EOF
    
    echo "‚úÖ Scaling test workloads created"
    echo "‚ö†Ô∏è  These workloads may trigger cluster scaling - monitor cluster-autoscaler logs"
    echo
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è monitoring tools
create_cluster_autoscaler_monitoring() {
    echo "=== Creating Cluster Autoscaler Monitoring Tools ==="
    
    cat << CA_MONITOR_EOF > cluster-autoscaler-monitoring.sh
#!/bin/bash

echo "=== Cluster Autoscaler Monitoring Tools ==="
echo "Tools for monitoring cluster autoscaling behavior"
echo

# Function to monitor cluster autoscaler in real-time
monitor_cluster_autoscaler() {
    echo "=== Real-time Cluster Autoscaler Monitoring ==="
    
    while true; do
        clear
        echo "Cluster Autoscaler Status - \$(date)"
        echo "=================================="
        echo
        
        # Cluster Autoscaler pod status
        echo "1. Cluster Autoscaler Pod:"
        kubectl get pods -n kube-system -l app=cluster-autoscaler --no-headers 2>/dev/null || echo "Cluster Autoscaler not found"
        echo
        
        # Node count and status
        echo "2. Node Status:"
        kubectl get nodes --no-headers | awk '{print \$2}' | sort | uniq -c
        echo "Total nodes: \$(kubectl get nodes --no-headers | wc -l)"
        echo
        
        # Pending pods
        echo "3. Pending Pods:"
        PENDING_COUNT=\$(kubectl get pods --all-namespaces --field-selector=status.phase=Pending --no-headers | wc -l)
        echo "Pending pods: \$PENDING_COUNT"
        if [ "\$PENDING_COUNT" -gt 0 ]; then
            kubectl get pods --all-namespaces --field-selector=status.phase=Pending -o custom-columns="NAMESPACE:.metadata.namespace,NAME:.metadata.name,REASON:.status.conditions[?(@.type=='PodScheduled')].reason" | head -5
        fi
        echo
        
        # Resource utilization
        echo "4. Node Resource Utilization:"
        kubectl top nodes 2>/dev/null | head -5 || echo "Metrics server not available"
        echo
        
        # Recent events
        echo "5. Recent Cluster Autoscaler Events:"
        kubectl get events -n kube-system --field-selector source=cluster-autoscaler --sort-by='.lastTimestamp' 2>/dev/null | tail -3 || echo "No recent events"
        echo
        
        echo "Press Ctrl+C to stop monitoring"
        sleep 10
    done
}

# Function to analyze scaling decisions
analyze_scaling_decisions() {
    echo "=== Analyzing Scaling Decisions ==="
    
    echo "1. Cluster Autoscaler Logs (last 50 lines):"
    echo "==========================================="
    kubectl logs -n kube-system -l app=cluster-autoscaler --tail=50 2>/dev/null | grep -E "(scale|node|pod)" || echo "No cluster autoscaler logs available"
    echo
    
    echo "2. Scale Up Events:"
    echo "=================="
    kubectl get events --all-namespaces --field-selector reason=TriggeredScaleUp --sort-by='.lastTimestamp' 2>/dev/null | tail -5 || echo "No scale up events found"
    echo
    
    echo "3. Scale Down Events:"
    echo "===================="
    kubectl get events --all-namespaces --field-selector reason=ScaleDown --sort-by='.lastTimestamp' 2>/dev/null | tail -5 || echo "No scale down events found"
    echo
    
    echo "4. Node Addition/Removal Events:"
    echo "==============================="
    kubectl get events --all-namespaces --field-selector involvedObject.kind=Node --sort-by='.lastTimestamp' 2>/dev/null | tail -10 || echo "No node events found"
    echo
}

# Function to test cluster scaling
test_cluster_scaling() {
    local test_type=\${1:-"scale-up"}
    
    echo "=== Testing Cluster Scaling: \$test_type ==="
    
    case "\$test_type" in
        "scale-up")
            echo "Creating workload to trigger scale up..."
            kubectl scale deployment resource-intensive-scale-test -n cluster-autoscaler-test --replicas=3 2>/dev/null || echo "Test deployment not found - run create_scaling_test_workloads first"
            ;;
        "scale-down")
            echo "Reducing workload to trigger scale down..."
            kubectl scale deployment resource-intensive-scale-test -n cluster-autoscaler-test --replicas=0 2>/dev/null
            kubectl scale deployment multiple-pods-scale-test -n cluster-autoscaler-test --replicas=0 2>/dev/null
            kubectl scale deployment anti-affinity-scale-test -n cluster-autoscaler-test --replicas=0 2>/dev/null
            ;;
        *)
            echo "Usage: test_cluster_scaling [scale-up|scale-down]"
            return 1
            ;;
    esac
    
    echo "Monitoring scaling for 5 minutes..."
    for i in {1..30}; do
        echo "Minute \$((i/6 + 1)): \$(date)"
        echo "Nodes: \$(kubectl get nodes --no-headers | wc -l)"
        echo "Pending pods: \$(kubectl get pods --all-namespaces --field-selector=status.phase=Pending --no-headers | wc -l)"
        echo "---"
        sleep 10
    done
    
    echo "‚úÖ Scaling test completed"
    echo
}

# Function to generate cluster autoscaler report
generate_cluster_autoscaler_report() {
    echo "=== Generating Cluster Autoscaler Report ==="
    
    local report_file="cluster-autoscaler-report-\$(date +%Y%m%d-%H%M%S).txt"
    
    {
        echo "HashFoundry HA Cluster Autoscaler Report"
        echo "========================================"
        echo "Generated: \$(date)"
        echo ""
        
        echo "=== CLUSTER AUTOSCALER STATUS ==="
        kubectl get pods -n kube-system -l app=cluster-autoscaler
        echo ""
        
        echo "=== NODE STATUS ==="
        kubectl get nodes
        echo ""
        
        echo "=== PENDING PODS ==="
        kubectl get pods --all-namespaces --field-selector=status.phase=Pending
        echo ""
        
        echo "=== RESOURCE UTILIZATION ==="
        kubectl top nodes 2>/dev/null || echo "Metrics server not available"
        echo ""
        
        echo "=== RECENT SCALING EVENTS ==="
        kubectl get events --all-namespaces --field-selector source=cluster-autoscaler --sort-by='.lastTimestamp' | tail -20
        echo ""
        
        echo "=== CLUSTER AUTOSCALER LOGS ==="
        kubectl logs -n kube-system -l app=cluster-autoscaler --tail=100 2>/dev/null || echo "Logs not available"
        echo ""
        
    } > "\$report_file"
    
    echo "‚úÖ Cluster Autoscaler report generated: \$report_file"
    echo
}

# Main function
main() {
    case "\$1" in
        "monitor")
            monitor_cluster_autoscaler
            ;;
        "analyze")
            analyze_scaling_decisions
            ;;
        "test")
            test_cluster_scaling "\$2"
            ;;
        "report")
            generate_cluster_autoscaler_report
            ;;
        *)
            echo "Usage: \$0 [action] [options]"
            echo ""
            echo "Actions:"
            echo "  monitor           - Real-time cluster autoscaler monitoring"
            echo "  analyze           - Analyze scaling decisions"
            echo "  test [type]       - Test cluster scaling (scale-up|scale-down)"
            echo "  report            - Generate cluster autoscaler report"
            echo ""
            echo "Examples:"
            echo "  \$0 monitor"
            echo "  \$0 analyze"
            echo "  \$0 test scale-up"
            echo "  \$0 report"
            ;;
    esac
}

# Run main function
main "\$@"

CA_MONITOR_EOF
    
    chmod +x cluster-autoscaler-monitoring.sh
    
    echo "‚úÖ Cluster Autoscaler monitoring tools created: cluster-autoscaler-monitoring.sh"
    echo
}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
main() {
    case "$1" in
        "analyze")
            analyze_cluster_autoscaler
            ;;
        "monitor-resources")
            monitor_cluster_resources
            ;;
        "test-workloads")
            create_scaling_test_workloads
            ;;
        "monitoring-tools")
            create_cluster_autoscaler_monitoring
            ;;
        "cleanup")
            # Cleanup test workloads
            kubectl delete namespace cluster-autoscaler-test --grace-period=0 2>/dev/null || true
            echo "‚úÖ Test workloads cleaned up"
            ;;
        "all"|"")
            analyze_cluster_autoscaler
            monitor_cluster_resources
            create_scaling_test_workloads
            create_cluster_autoscaler_monitoring
            ;;
        *)
            echo "Usage: $0 [action]"
            echo ""
            echo "Actions:"
            echo "  analyze           - Analyze cluster autoscaler status"
            echo "  monitor-resources - Monitor cluster resources"
            echo "  test-workloads    - Create test workloads for scaling"
            echo "  monitoring-tools  - Create monitoring tools"
            echo "  cleanup           - Cleanup test workloads"
            echo "  all               - Run all actions (default)"
            echo ""
            echo "Examples:"
            echo "  $0 analyze"
            echo "  $0 test-workloads"
            echo "  $0 cleanup"
            ;;
    esac
}

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
main "$@"

EOF

chmod +x kubernetes-cluster-autoscaler-toolkit.sh

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ Cluster Autoscaler toolkit
./kubernetes-cluster-autoscaler-toolkit.sh all
```

## üìã **Cluster Autoscaler –≤ DigitalOcean:**

### **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ .env:**
```bash
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ ha/.env
AUTO_SCALE_ENABLED=true
MIN_NODES=3
MAX_NODES=9
```

### **Scaling Triggers:**

| **Trigger** | **Action** | **Condition** | **Time** |
|-------------|------------|---------------|----------|
| **Pending Pods** | Scale Up | Pod'—ã –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã | ~1-3 –º–∏–Ω—É—Ç—ã |
| **Low Utilization** | Scale Down | –£–∑–µ–ª –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è <50% | ~10-15 –º–∏–Ω—É—Ç |
| **Empty Node** | Scale Down | –ù–µ—Ç Pod'–æ–≤ –Ω–∞ —É–∑–ª–µ | ~10 –º–∏–Ω—É—Ç |
| **Resource Pressure** | Scale Up | –ù–µ—Ö–≤–∞—Ç–∫–∞ CPU/Memory | –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ |

## üéØ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã:**

### **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:**
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å Cluster Autoscaler toolkit
./kubernetes-cluster-autoscaler-toolkit.sh all

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
./cluster-autoscaler-monitoring.sh monitor

# –ê–Ω–∞–ª–∏–∑ —Ä–µ—à–µ–Ω–∏–π –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
./cluster-autoscaler-monitoring.sh analyze
```

### **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:**
```bash
# –°–æ–∑–¥–∞—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –¥–ª—è scale up
./cluster-autoscaler-monitoring.sh test scale-up

# –£–º–µ–Ω—å—à–∏—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –¥–ª—è scale down
./cluster-autoscaler-monitoring.sh test scale-down
```

### **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É–∑–ª—ã
kubectl get nodes

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å pending pods
kubectl get pods --all-namespaces --field-selector=status.phase=Pending

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
kubectl get events --field-selector source=cluster-autoscaler
```

## üîß **Best Practices –¥–ª—è Cluster Autoscaler:**

### **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
- **Set appropriate min/max** - —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ min/max
- **Configure node pools** - –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ –ø—É–ª—ã —É–∑–ª–æ–≤
- **Set resource requests** - —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤
- **Use PodDisruptionBudgets** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ PDB

### **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:**
- **Monitor scaling events** - –º–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —Å–æ–±—ã—Ç–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
- **Track costs** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ —Ä–∞—Å—Ö–æ–¥—ã
- **Set up alerts** - –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –æ–ø–æ–≤–µ—â–µ–Ω–∏—è
- **Regular review** - —Ä–µ–≥—É–ª—è—Ä–Ω–æ –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### **Troubleshooting:**
- **Check pending pods** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ pending Pod'—ã
- **Verify node capacity** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –µ–º–∫–æ—Å—Ç—å —É–∑–ª–æ–≤
- **Review scaling policies** - –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –ø–æ–ª–∏—Ç–∏–∫–∏
- **Monitor cloud provider limits** - –º–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ª–∏–º–∏—Ç—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

**Cluster Autoscaler –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã!**
