# Grafana Alerting Setup Guide

## ðŸŽ¯ **ÐžÐ±Ð·Ð¾Ñ€**
ÐŸÐ¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ðµ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð¿Ð¾ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð² Ð² Grafana Ñ‡ÐµÑ€ÐµÐ· Ð²ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ, Ð¿Ð¾ÑÐºÐ¾Ð»ÑŒÐºÑƒ Helm chart Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ‚Ð¸Ð²Ð½ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð².

## ðŸ” **Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ðº Grafana**

### **Ð§ÐµÑ€ÐµÐ· Ingress (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ):**
```bash
# Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² /etc/hosts
echo "129.212.169.0 grafana.hashfoundry.local" >> /etc/hosts

# ÐžÑ‚ÐºÑ€Ñ‹Ñ‚ÑŒ Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ðµ
https://grafana.hashfoundry.local
```

### **Ð§ÐµÑ€ÐµÐ· Port-Forward:**
```bash
kubectl port-forward -n monitoring svc/grafana 3000:80
# ÐžÑ‚ÐºÑ€Ñ‹Ñ‚ÑŒ: http://localhost:3000
```

### **Ð£Ñ‡ÐµÑ‚Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ:**
- **Username**: `admin`
- **Password**: `admin`

## ðŸ“Š **Ð¨Ð°Ð³ 1: ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Data Sources**

1. Ð’Ð¾Ð¹Ñ‚Ð¸ Ð² Grafana UI
2. ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð² **Configuration** â†’ **Data Sources**
3. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÑŒÑÑ, Ñ‡Ñ‚Ð¾ Prometheus Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½:
   - **Name**: Prometheus
   - **URL**: `http://prometheus-server.monitoring.svc.cluster.local`
   - **Access**: Server (default)

## ðŸš¨ **Ð¨Ð°Ð³ 2: ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Contact Points**

### **2.1 Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Email Contact Point:**
1. ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð² **Alerting** â†’ **Contact points**
2. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New contact point**
3. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Name**: `email-alerts`
   - **Contact point type**: `Email`
   - **Addresses**: `admin@hashfoundry.local`
   - **Subject**: `ðŸš¨ Grafana Alert: {{ .GroupLabels.alertname }}`
   - **Message**: 
     ```
     {{ range .Alerts }}
     Alert: {{ .Annotations.summary }}
     Description: {{ .Annotations.description }}
     Status: {{ .Status }}
     Severity: {{ .Labels.severity }}
     {{ end }}
     ```
4. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save contact point**

### **2.2 Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Slack Contact Point (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾):**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New contact point**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Name**: `slack-alerts`
   - **Contact point type**: `Slack`
   - **Webhook URL**: `YOUR_SLACK_WEBHOOK_URL`
   - **Channel**: `#alerts`
   - **Title**: `ðŸš¨ Grafana Alert`
   - **Text**: 
     ```
     {{ range .Alerts }}
     Alert: {{ .Annotations.summary }}
     Description: {{ .Annotations.description }}
     {{ end }}
     ```
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save contact point**

## ðŸ“‹ **Ð¨Ð°Ð³ 3: ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Notification Policies**

1. ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð² **Alerting** â†’ **Notification policies**
2. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Edit** Ð½Ð° Default policy
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ:
   - **Contact point**: `email-alerts`
   - **Group by**: `alertname`
   - **Group wait**: `10s`
   - **Group interval**: `5m`
   - **Repeat interval**: `12h`

### **3.1 Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Add nested policy**
2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ:
   - **Matching labels**: `severity = critical`
   - **Contact point**: `email-alerts`
   - **Group wait**: `5s`
   - **Group interval**: `2m`
   - **Repeat interval**: `6h`

### **3.2 Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ð¹:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Add nested policy**
2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ:
   - **Matching labels**: `severity = warning`
   - **Contact point**: `slack-alerts` (ÐµÑÐ»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½)
   - **Group wait**: `10s`
   - **Group interval**: `5m`
   - **Repeat interval**: `1h`

## âš ï¸ **Ð¨Ð°Ð³ 4: Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Alert Rules**

### **4.1 Node Down Alert:**
1. ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð² **Alerting** â†’ **Alert rules**
2. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
3. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `Node Down`
   - **Folder**: `Kubernetes` (ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÐµÑÐ»Ð¸ Ð½ÐµÑ‚)
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `up{job="kubernetes-nodes"} == 0`
   - **Condition**: `IS BELOW 1`
   - **Evaluation**: 
     - **For**: `5m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `critical`
   - **Annotations**:
     - `summary`: `Node {{ $labels.instance }} is down`
     - `description`: `Node {{ $labels.instance }} has been down for more than 5 minutes`
4. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

### **4.2 High CPU Usage Alert:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `High CPU Usage`
   - **Folder**: `Kubernetes`
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)`
   - **Condition**: `IS ABOVE 80`
   - **Evaluation**: 
     - **For**: `5m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `warning`
   - **Annotations**:
     - `summary`: `High CPU usage on {{ $labels.instance }}`
     - `description`: `CPU usage is above 80% for more than 5 minutes`
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

### **4.3 High Memory Usage Alert:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `High Memory Usage`
   - **Folder**: `Kubernetes`
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100`
   - **Condition**: `IS ABOVE 90`
   - **Evaluation**: 
     - **For**: `5m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `critical`
   - **Annotations**:
     - `summary`: `High memory usage on {{ $labels.instance }}`
     - `description`: `Memory usage is above 90% for more than 5 minutes`
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

### **4.4 Low Disk Space Alert:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `Low Disk Space`
   - **Folder**: `Kubernetes`
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `(1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100`
   - **Condition**: `IS ABOVE 85`
   - **Evaluation**: 
     - **For**: `5m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `warning`
   - **Annotations**:
     - `summary`: `Low disk space on {{ $labels.instance }}`
     - `description`: `Disk usage is above 85% on {{ $labels.mountpoint }}`
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

### **4.5 ArgoCD Application Not Synced:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `ArgoCD Application Not Synced`
   - **Folder**: `ArgoCD` (ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÐµÑÐ»Ð¸ Ð½ÐµÑ‚)
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `argocd_app_info{sync_status!="Synced"}`
   - **Condition**: `IS ABOVE 0`
   - **Evaluation**: 
     - **For**: `15m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `warning`
   - **Annotations**:
     - `summary`: `ArgoCD application {{ $labels.name }} not synced`
     - `description`: `Application {{ $labels.name }} in project {{ $labels.project }} is not synced for more than 15 minutes`
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

### **4.6 ArgoCD Application Unhealthy:**
1. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **New rule**
2. Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ:
   - **Rule name**: `ArgoCD Application Unhealthy`
   - **Folder**: `ArgoCD`
   - **Query A**: 
     - **Data source**: Prometheus
     - **Query**: `argocd_app_info{health_status!="Healthy"}`
   - **Condition**: `IS ABOVE 0`
   - **Evaluation**: 
     - **For**: `10m`
     - **Evaluate every**: `1m`
   - **Labels**:
     - `severity`: `critical`
   - **Annotations**:
     - `summary`: `ArgoCD application {{ $labels.name }} unhealthy`
     - `description`: `Application {{ $labels.name }} in project {{ $labels.project }} is unhealthy`
3. ÐÐ°Ð¶Ð°Ñ‚ÑŒ **Save rule and exit**

## ðŸ§ª **Ð¨Ð°Ð³ 5: Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²**

### **5.1 Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð»ÐµÑ€Ñ‚Ð°:**
```bash
# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð´Ð° Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¼ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð»ÐµÐ½Ð¸ÐµÐ¼ CPU
cat > test-high-cpu.yaml << 'EOF'
apiVersion: v1
kind: Pod
metadata:
  name: cpu-stress-test
  namespace: default
spec:
  containers:
  - name: cpu-stress
    image: progrium/stress
    args: ["--cpu", "2", "--timeout", "300s"]
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 2000m
        memory: 256Mi
EOF

kubectl apply -f test-high-cpu.yaml
```

### **5.2 ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ Ð°Ð»ÐµÑ€Ñ‚Ð°:**
1. ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð°Ñ‚ÑŒ 5-10 Ð¼Ð¸Ð½ÑƒÑ‚
2. ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð² **Alerting** â†’ **Alert rules**
3. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° **High CPU Usage**
4. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ **Alerting** â†’ **Alerts** Ð´Ð»Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²

### **5.3 ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð´Ð°:**
```bash
kubectl delete -f test-high-cpu.yaml
rm test-high-cpu.yaml
```

## ðŸ“§ **Ð¨Ð°Ð³ 6: ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° SMTP (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)**

Ð”Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ email ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹ Ð½ÑƒÐ¶Ð½Ð¾ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ SMTP:

### **6.1 ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Grafana ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸:**
```bash
# Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ values.yaml
cd ha/k8s/addons/monitoring/grafana
```

Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² `grafana.ini`:
```yaml
grafana.ini:
  smtp:
    enabled: true
    host: smtp.gmail.com:587
    user: your-email@gmail.com
    password: your-app-password
    from_address: your-email@gmail.com
    from_name: Grafana HashFoundry
```

### **6.2 ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Grafana:**
```bash
make upgrade
```

## ðŸ“Š **Ð¨Ð°Ð³ 7: ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²**

### **7.1 Ð§ÐµÑ€ÐµÐ· Grafana UI:**
1. **Alerting** â†’ **Alert rules** - ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… Ð¿Ñ€Ð°Ð²Ð¸Ð»
2. **Alerting** â†’ **Alerts** - Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð°Ð»ÐµÑ€Ñ‚Ñ‹
3. **Alerting** â†’ **Silences** - Ð·Ð°Ð³Ð»ÑƒÑˆÐµÐ½Ð½Ñ‹Ðµ Ð°Ð»ÐµÑ€Ñ‚Ñ‹
4. **Alerting** â†’ **Contact points** - Ñ‚Ð¾Ñ‡ÐºÐ¸ ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð°
5. **Alerting** â†’ **Notification policies** - Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹

### **7.2 Ð§ÐµÑ€ÐµÐ· API:**
```bash
# ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÑÐµÑ… Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²
curl -u admin:admin http://localhost:3000/api/alertmanager/grafana/api/v1/alerts

# ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð» Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²
curl -u admin:admin http://localhost:3000/api/ruler/grafana/api/v1/rules
```

## ðŸ”§ **Troubleshooting**

### **ÐÐ»ÐµÑ€Ñ‚Ñ‹ Ð½Ðµ ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚:**
1. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Data Source Prometheus
2. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Query Ð² Ð¿Ñ€Ð°Ð²Ð¸Ð»Ðµ Ð°Ð»ÐµÑ€Ñ‚Ð°
3. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Evaluation Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
4. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð»Ð¾Ð³Ð¸ Grafana: `kubectl logs -n monitoring -l app.kubernetes.io/name=grafana`

### **Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ Ð½Ðµ Ð¿Ñ€Ð¸Ñ…Ð¾Ð´ÑÑ‚:**
1. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Contact Points
2. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Notification Policies
3. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ SMTP Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ (ÐµÑÐ»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ email)
4. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Webhook URL (ÐµÑÐ»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Slack)

### **ÐŸÐ¾Ð»ÐµÐ·Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:**
```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Grafana
kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana

# Ð›Ð¾Ð³Ð¸ Grafana
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana --tail=100

# Port-forward Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°
kubectl port-forward -n monitoring svc/grafana 3000:80

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
kubectl get configmap -n monitoring grafana -o yaml
```

## ðŸ“‹ **Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ‡ÐµÐºÐ»Ð¸ÑÑ‚**

### **âœ… ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°:**
- [ ] Grafana Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ñ‡ÐµÑ€ÐµÐ· Ingress
- [ ] Data Source Prometheus Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½
- [ ] Contact Points ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹
- [ ] Notification Policies Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹
- [ ] Alert Rules ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹:
  - [ ] Node Down
  - [ ] High CPU Usage
  - [ ] High Memory Usage
  - [ ] Low Disk Space
  - [ ] ArgoCD Application Not Synced
  - [ ] ArgoCD Application Unhealthy
- [ ] Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð² Ð¿Ñ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð¾
- [ ] SMTP Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)

### **ðŸŽ¯ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚:**
ÐŸÐ¾Ð»Ð½Ð¾Ñ†ÐµÐ½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð² Ð² Grafana Ð³Ð¾Ñ‚Ð¾Ð²Ð° Ðº production Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ñ:
- âœ… **ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹** (CPU, Memory, Disk, Nodes)
- âœ… **ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ArgoCD** (Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð¸Ñ… ÑÑ‚Ð°Ñ‚ÑƒÑ)
- âœ… **Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ** Ñ‡ÐµÑ€ÐµÐ· Email/Slack
- âœ… **Ð“Ð¸Ð±ÐºÐ¸Ðµ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ¸** Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð² Ð°Ð»ÐµÑ€Ñ‚Ð¾Ð²
- âœ… **Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ** Ð¸ troubleshooting

---

**Ð”Ð°Ñ‚Ð° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ**: 16.07.2025  
**Ð’ÐµÑ€ÑÐ¸Ñ**: 1.0.0  
**Ð¡Ñ‚Ð°Ñ‚ÑƒÑ**: âœ… Production Ready
